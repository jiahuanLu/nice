{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c22a955",
   "metadata": {},
   "source": [
    "## 爬取古泉园地网站内的图片\n",
    "### 1、Crawler 类是爬图片的实现类\n",
    "### 2、Test 类是单元测试类，可以在里面写针对每个函数的测试方法\n",
    "### 3、Main 类是主程序执行类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class Crawler:\n",
    "    \n",
    "    url = \"\"\n",
    "    headers = \"\"\n",
    "    savePath = \"\"\n",
    "    soupContent = BeautifulSoup() \n",
    "    \n",
    "    def __init__(self, url, headers, savePath):\n",
    "        self.url = url\n",
    "        self.headers = headers\n",
    "        self.savePath = savePath\n",
    "        self.get_response_info()\n",
    "    \n",
    "    # 加载soupContent的内容\n",
    "    def get_response_info(self):\n",
    "        response = requests.get(self.url, headers = self.headers)\n",
    "        self.soupContent = BeautifulSoup(response.content, \"html.parser\")  #第一个参数传response.text也是可以的，但是解析慢\n",
    "        \n",
    "    # 抓取总共多少页图片\n",
    "    def catch_page_sizes(self):\n",
    "        pageScope = self.soupContent.findAll(name=\"div\", attrs={\"class\":\"r_float filter-r f-filter-r\"})\n",
    "        labelAList = pageScope[0].find_all('a')\n",
    "        listLength = len(labelAList)\n",
    "        return labelAList[listLength - 1].get_text()\n",
    "        \n",
    "    # 捕获图片所在区域的所有div    \n",
    "    def get_div_lists(self):\n",
    "        return self.soupContent.findAll(name=\"div\", attrs={\"class\":\"gq-box-detail\"})\n",
    "        \n",
    "    # 捕获所有图片区域的list数组    \n",
    "    def iterate_div_lists(self, divLists):\n",
    "        for eachDiv in divLists:\n",
    "            moneyInfo = self.catch_price(eachDiv)\n",
    "            self.download_and_save_images(self.catch_img_url(eachDiv), \n",
    "                                          self.catch_name(eachDiv))\n",
    "    # 捕获图片的url地址\n",
    "    def catch_img_url(self, eachDiv):\n",
    "        imgDiv = eachDiv.find_all(name=\"div\", attrs={\"class\" :\"div-imgs\"})\n",
    "        imgSrc = imgDiv[0].find_all('img')\n",
    "        imgUrl = imgSrc[0]['data-original']#获取链接\n",
    "        return imgUrl\n",
    "        \n",
    "    # 捕获图片的名称    \n",
    "    def catch_name(self, eachDiv):\n",
    "        nameDiv = eachDiv.find_all(name=\"div\", attrs={\"class\":\"div-name\"})\n",
    "        imgName = nameDiv[0].get_text()\n",
    "        return imgName\n",
    "        \n",
    "    # 捕获图片对应钱币的价格    \n",
    "    def catch_price(self, eachDiv):\n",
    "        priceDiv = eachDiv.find_all(name=\"div\", attrs={\"class\":\"div-price\"})\n",
    "        moneyFlag = priceDiv[0].find_all('em')[0].get_text()\n",
    "        moneyNum = priceDiv[0].find_all('i')[0].get_text()\n",
    "        return ({\"moneyFlag\":moneyFlag, \"moneyNum\":moneyNum})\n",
    "        \n",
    "    # 捕获图片对应钱币的介绍信息    \n",
    "    def catch_description(self, eachDiv):\n",
    "        priceDiv = eachDiv.find_all(name=\"div\", attrs={\"class\":\"div-specification\"})\n",
    "        coinDescription = priceDiv[0].find_all('i')[0].get_text()\n",
    "        print(\"====================================================\")\n",
    "        return coinDescription\n",
    "        \n",
    "    # 下载并保存抓取到的图片    \n",
    "    def download_and_save_images(self, imgUrl, imgName):\n",
    "        imgResponse = requests.get(imgUrl, headers = self.headers)\n",
    "        with open(str(self.savePath) + str(imgName).strip() + \".jpg\", 'wb') as f:    #/为分级 wb代表二进制模式文件，允许写入文件，\n",
    "            f.write(imgResponse.content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbe8adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单元测试类\n",
    "class Test:\n",
    "    baseUrl = 'https://tuku.chcoin.com/'\n",
    "    url = baseUrl + \"listing-0-0-1-1.html\"\n",
    "    imageSavePath = '/Users/lujiahuan/4projects/yolov5+javaweb/yolov5/images/test_images/'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.88 Safari/537.36'}\n",
    "\n",
    "    def unit_test(self):\n",
    "        crawler = Crawler(self.url, self.headers, self.imageSavePath)\n",
    "        print(crawler.catch_page_sizes())    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc044c1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 主函数类\n",
    "class Main:\n",
    "    baseUrl = 'https://tuku.chcoin.com/'\n",
    "    firstPageUrl = baseUrl + \"listing-0-0-1-1.html\"\n",
    "    imageSavePath = '/Users/lujiahuan/4projects/yolov5+javaweb/yolov5/images/test_images/'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.88 Safari/537.36'}\n",
    "\n",
    "    def main(self):\n",
    "        crawler = Crawler(self.firstPageUrl, self.headers, self.imageSavePath)\n",
    "        pageSize = crawler.catch_page_sizes()\n",
    "        print(pageSize)\n",
    "        for x in range(500):  # 这里的20如果改用上面的pageSize的话，太多图片了\n",
    "            if x == 0:\n",
    "                pass\n",
    "            else:\n",
    "                url = self.baseUrl + \"listing-0-0-1-\" + str(x) + \".html\"\n",
    "                crawler = Crawler(url, self.headers, self.imageSavePath)\n",
    "                crawler.iterate_div_lists(crawler.get_div_lists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca0e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test().unit_test()  # 单元测试\n",
    "\n",
    "# TODO:获取图片的函数还可以优化（如果获取的图片地址有误，则程序不终端，继续往后执行）\n",
    "Main().main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe7e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da642553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
